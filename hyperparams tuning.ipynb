{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовал\n",
    "git\n",
    "dataset по раковым клеткам груди\n",
    "все через pip install\n",
    "gridsearch\n",
    "\n",
    "\n",
    "Скачать можно все, установив git и выполнивы команду \n",
    "```\n",
    "git clone https://github.com/sbatururimi/teaching_wed5_light.git\n",
    "```\n",
    "\n",
    "Затем:\n",
    "1) создать окружение с conda/virtualenv c python3.6 или выше\n",
    "2) активировать окружение\n",
    "3) выполнить\n",
    "```\n",
    "pip install -r pip_requirements.txt\n",
    "```\n",
    "(файл в комплекте)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://git-scm.com/downloads\n",
    "https://keras.io/search.html?q=fit\n",
    "https://www.tensorflow.org/guide/keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import wrangle as wr\n",
    "\n",
    "from numpy import nan\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: run: command not found\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_knobs.png               4_babysitting.png         7_early stopping.png\r\n",
      "2_dnn.png                 5_gridsearch.png          breast_cancer.csv\r\n",
      "3_iterative process.png   6_random search.png       hyperparams tuning.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5    843786         M        12.45         15.70           82.57      477.1   \n",
       "6    844359         M        18.25         19.98          119.60     1040.0   \n",
       "7  84458202         M        13.71         20.83           90.20      577.9   \n",
       "8    844981         M        13.00         21.82           87.50      519.8   \n",
       "9  84501001         M        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "5  ...          23.75           103.40       741.6            0.1791   \n",
       "6  ...          27.66           153.20      1606.0            0.1442   \n",
       "7  ...          28.14           110.60       897.0            0.1654   \n",
       "8  ...          30.73           106.20       739.3            0.1703   \n",
       "9  ...          40.68            97.65       711.4            0.1853   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "5             0.5249           0.5355                0.1741          0.3985   \n",
       "6             0.2576           0.3784                0.1932          0.3063   \n",
       "7             0.3682           0.2678                0.1556          0.3196   \n",
       "8             0.5401           0.5390                0.2060          0.4378   \n",
       "9             1.0580           1.1050                0.2210          0.4366   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "5                  0.12440          NaN  \n",
       "6                  0.08368          NaN  \n",
       "7                  0.11510          NaN  \n",
       "8                  0.10720          NaN  \n",
       "9                  0.20750          NaN  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"breast_cancer.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 32\", axis=1, inplace=True)\n",
    "df.drop(\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    M\n",
       "1    M\n",
       "2    M\n",
       "3    M\n",
       "4    M\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"diagnosis\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.diagnosis.values\n",
    "x = df.drop(\"diagnosis\", axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'B' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M'\n",
      " 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B'\n",
      " 'M' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'M' 'M' 'B' 'B'\n",
      " 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B'\n",
      " 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'B'\n",
      " 'M' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'B'\n",
      " 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'M'\n",
      " 'M' 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B'\n",
      " 'M' 'M' 'M' 'B' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'M' 'M'\n",
      " 'M' 'M' 'B' 'M' 'M' 'M' 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'M' 'M'\n",
      " 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'M'\n",
      " 'B' 'B' 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'B'\n",
      " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'M'\n",
      " 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'B'\n",
      " 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B'\n",
      " 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B'\n",
      " 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B'\n",
      " 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'B' 'M'\n",
      " 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'B' 'M'\n",
      " 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'M'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'M' 'M' 'B']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.096100</td>\n",
       "      <td>-2.071512</td>\n",
       "      <td>1.268817</td>\n",
       "      <td>0.983510</td>\n",
       "      <td>1.567087</td>\n",
       "      <td>3.280628</td>\n",
       "      <td>2.650542</td>\n",
       "      <td>2.530249</td>\n",
       "      <td>2.215566</td>\n",
       "      <td>2.253764</td>\n",
       "      <td>...</td>\n",
       "      <td>1.885031</td>\n",
       "      <td>-1.358098</td>\n",
       "      <td>2.301575</td>\n",
       "      <td>1.999478</td>\n",
       "      <td>1.306537</td>\n",
       "      <td>2.614365</td>\n",
       "      <td>2.107672</td>\n",
       "      <td>2.294058</td>\n",
       "      <td>2.748204</td>\n",
       "      <td>1.935312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.828212</td>\n",
       "      <td>-0.353322</td>\n",
       "      <td>1.684473</td>\n",
       "      <td>1.907030</td>\n",
       "      <td>-0.826235</td>\n",
       "      <td>-0.486643</td>\n",
       "      <td>-0.023825</td>\n",
       "      <td>0.547662</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>-0.867889</td>\n",
       "      <td>...</td>\n",
       "      <td>1.804340</td>\n",
       "      <td>-0.368879</td>\n",
       "      <td>1.533776</td>\n",
       "      <td>1.888827</td>\n",
       "      <td>-0.375282</td>\n",
       "      <td>-0.430066</td>\n",
       "      <td>-0.146620</td>\n",
       "      <td>1.086129</td>\n",
       "      <td>-0.243675</td>\n",
       "      <td>0.280943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.578499</td>\n",
       "      <td>0.455786</td>\n",
       "      <td>1.565126</td>\n",
       "      <td>1.557513</td>\n",
       "      <td>0.941382</td>\n",
       "      <td>1.052000</td>\n",
       "      <td>1.362280</td>\n",
       "      <td>2.035440</td>\n",
       "      <td>0.938859</td>\n",
       "      <td>-0.397658</td>\n",
       "      <td>...</td>\n",
       "      <td>1.510541</td>\n",
       "      <td>-0.023953</td>\n",
       "      <td>1.346291</td>\n",
       "      <td>1.455004</td>\n",
       "      <td>0.526944</td>\n",
       "      <td>1.081980</td>\n",
       "      <td>0.854222</td>\n",
       "      <td>1.953282</td>\n",
       "      <td>1.151242</td>\n",
       "      <td>0.201214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768233</td>\n",
       "      <td>0.253509</td>\n",
       "      <td>-0.592166</td>\n",
       "      <td>-0.763792</td>\n",
       "      <td>3.280667</td>\n",
       "      <td>3.399917</td>\n",
       "      <td>1.914213</td>\n",
       "      <td>1.450431</td>\n",
       "      <td>2.864862</td>\n",
       "      <td>4.906602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281217</td>\n",
       "      <td>0.133866</td>\n",
       "      <td>-0.249720</td>\n",
       "      <td>-0.549538</td>\n",
       "      <td>3.391291</td>\n",
       "      <td>3.889975</td>\n",
       "      <td>1.987839</td>\n",
       "      <td>2.173873</td>\n",
       "      <td>6.040726</td>\n",
       "      <td>4.930672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.748758</td>\n",
       "      <td>-1.150804</td>\n",
       "      <td>1.775011</td>\n",
       "      <td>1.824624</td>\n",
       "      <td>0.280125</td>\n",
       "      <td>0.538866</td>\n",
       "      <td>1.369806</td>\n",
       "      <td>1.427237</td>\n",
       "      <td>-0.009552</td>\n",
       "      <td>-0.561956</td>\n",
       "      <td>...</td>\n",
       "      <td>1.297434</td>\n",
       "      <td>-1.465481</td>\n",
       "      <td>1.337363</td>\n",
       "      <td>1.219651</td>\n",
       "      <td>0.220362</td>\n",
       "      <td>-0.313119</td>\n",
       "      <td>0.612640</td>\n",
       "      <td>0.728618</td>\n",
       "      <td>-0.867590</td>\n",
       "      <td>-0.396751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.096100 -2.071512  1.268817  0.983510  1.567087  3.280628  2.650542   \n",
       "1  1.828212 -0.353322  1.684473  1.907030 -0.826235 -0.486643 -0.023825   \n",
       "2  1.578499  0.455786  1.565126  1.557513  0.941382  1.052000  1.362280   \n",
       "3 -0.768233  0.253509 -0.592166 -0.763792  3.280667  3.399917  1.914213   \n",
       "4  1.748758 -1.150804  1.775011  1.824624  0.280125  0.538866  1.369806   \n",
       "\n",
       "         7         8         9   ...        20        21        22        23  \\\n",
       "0  2.530249  2.215566  2.253764  ...  1.885031 -1.358098  2.301575  1.999478   \n",
       "1  0.547662  0.001391 -0.867889  ...  1.804340 -0.368879  1.533776  1.888827   \n",
       "2  2.035440  0.938859 -0.397658  ...  1.510541 -0.023953  1.346291  1.455004   \n",
       "3  1.450431  2.864862  4.906602  ... -0.281217  0.133866 -0.249720 -0.549538   \n",
       "4  1.427237 -0.009552 -0.561956  ...  1.297434 -1.465481  1.337363  1.219651   \n",
       "\n",
       "         24        25        26        27        28        29  \n",
       "0  1.306537  2.614365  2.107672  2.294058  2.748204  1.935312  \n",
       "1 -0.375282 -0.430066 -0.146620  1.086129 -0.243675  0.280943  \n",
       "2  0.526944  1.081980  0.854222  1.953282  1.151242  0.201214  \n",
       "3  3.391291  3.889975  1.987839  2.173873  6.040726  4.930672  \n",
       "4  0.220362 -0.313119  0.612640  0.728618 -0.867590 -0.396751  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize every features to mean 0, std 1 \n",
    "df = pd.DataFrame(x)  \n",
    "x = (df - df.mean()) / df.std()\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09609953, -2.0715123 ,  1.26881726, ...,  2.2940576 ,\n",
       "         2.74820411,  1.93531174],\n",
       "       [ 1.82821197, -0.35332152,  1.68447255, ...,  1.08612862,\n",
       "        -0.24367526,  0.28094279],\n",
       "       [ 1.5784992 ,  0.45578591,  1.56512598, ...,  1.95328166,\n",
       "         1.15124203,  0.20121416],\n",
       "       ...,\n",
       "       [ 0.70166686,  2.04377549,  0.67208442, ...,  0.41370467,\n",
       "        -1.10357792, -0.31812924],\n",
       "       [ 1.83672491,  2.33440316,  1.98078127, ...,  2.28797231,\n",
       "         1.9173959 ,  2.21768395],\n",
       "       [-1.80681144,  1.22071793, -1.81279344, ..., -1.7435287 ,\n",
       "        -0.04809589, -0.75054629]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "def create_model(first_neuron=9, activation=\"relu\", \n",
    "                 kernel_initializer=\"uniform\", dropout_rate=0, optimizer=\"Adam\"):\n",
    "    \"\"\"Neural network creation\n",
    "    \n",
    "    Args:\n",
    "     first_neuron:....\n",
    "     \n",
    "    Returns:\n",
    "    \n",
    "    Assertions:\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(first_neuron,\n",
    "                   input_dim=input_dim,\n",
    "                   kernel_initializer=kernel_initializer))\n",
    "    \n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=kernel_initializer, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_model in module __main__:\n",
      "\n",
      "create_model(first_neuron=9, activation='relu', kernel_initializer='uniform', dropout_rate=0, optimizer='Adam')\n",
      "    Neural network creation\n",
      "    \n",
      "    Args:\n",
      "     first_neuron:....\n",
      "     \n",
      "    Returns:\n",
      "    \n",
      "    Assertions:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_neurons = [8,9]\n",
    "activation = [\"relu\", \"elu\"]\n",
    "kernel_initializer = [\"uniform\", \"normal\"]\n",
    "optimizer = [\"Adam\", \"Nadam\"]\n",
    "\n",
    "epochs=[10]\n",
    "batch_size = [1024]\n",
    "dropout_rate = [0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(epochs = epochs,\n",
    "                 batch_size=batch_size,\n",
    "                optimizer=optimizer,\n",
    "                 dropout_rate=dropout_rate,\n",
    "                 kernel_initializer=kernel_initializer,\n",
    "                 first_neuron=first_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': [10],\n",
       " 'batch_size': [1024],\n",
       " 'optimizer': ['Adam', 'Nadam'],\n",
       " 'dropout_rate': [0.0],\n",
       " 'kernel_initializer': ['uniform', 'normal'],\n",
       " 'first_neuron': [8, 9]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=uniform, optimizer=Adam \n",
      "WARNING:tensorflow:From /Users/virt/Developer/teaching/workshops/wed/jun5/hypertuning/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/virt/Developer/teaching/workshops/wed/jun5/hypertuning/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 2ms/step - loss: 0.6928 - acc: 0.4965\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 0s 22us/step - loss: 0.6907 - acc: 0.6338\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 0s 17us/step - loss: 0.6887 - acc: 0.7817\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 0s 52us/step - loss: 0.6866 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 0s 23us/step - loss: 0.6846 - acc: 0.9225\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 0s 13us/step - loss: 0.6825 - acc: 0.9437\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 0s 22us/step - loss: 0.6803 - acc: 0.9577\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 0s 37us/step - loss: 0.6781 - acc: 0.9542\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 0s 23us/step - loss: 0.6758 - acc: 0.9542\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 0s 19us/step - loss: 0.6734 - acc: 0.9613\n",
      "285/285 [==============================] - 0s 370us/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=uniform, optimizer=Adam, total=   1.4s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=uniform, optimizer=Adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.6928 - acc: 0.5579\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 0s 7us/step - loss: 0.6913 - acc: 0.7123\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.6898 - acc: 0.7544\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 0s 8us/step - loss: 0.6882 - acc: 0.8211\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 0s 54us/step - loss: 0.6866 - acc: 0.8596\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.6849 - acc: 0.8632\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.6832 - acc: 0.8737\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 0s 9us/step - loss: 0.6814 - acc: 0.8807\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.6796 - acc: 0.8842\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.6776 - acc: 0.8842\n",
      "284/284 [==============================] - 0s 372us/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=uniform, optimizer=Adam, total=   1.7s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=uniform, optimizer=Nadam \n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.6907 - acc: 0.7606\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 0s 11us/step - loss: 0.6873 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 0s 7us/step - loss: 0.6846 - acc: 0.9049\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 0s 10us/step - loss: 0.6819 - acc: 0.9085\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 0s 8us/step - loss: 0.6789 - acc: 0.9190\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 0s 10us/step - loss: 0.6755 - acc: 0.9261\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 0s 13us/step - loss: 0.6717 - acc: 0.9331\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 0s 12us/step - loss: 0.6673 - acc: 0.9401\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 0s 12us/step - loss: 0.6623 - acc: 0.9401\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 0s 16us/step - loss: 0.6567 - acc: 0.9437\n",
      "285/285 [==============================] - 0s 362us/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=uniform, optimizer=Nadam, total=   1.9s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=uniform, optimizer=Nadam \n",
      "Epoch 1/10\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.6898 - acc: 0.8035\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 0s 11us/step - loss: 0.6861 - acc: 0.8632\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 0s 29us/step - loss: 0.6827 - acc: 0.8982\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.6796 - acc: 0.9123\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.6767 - acc: 0.9123\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.6735 - acc: 0.9158\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 0s 30us/step - loss: 0.6699 - acc: 0.9123\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.6659 - acc: 0.9123\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.6614 - acc: 0.9158\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 0s 19us/step - loss: 0.6564 - acc: 0.9228\n",
      "284/284 [==============================] - 0s 619us/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=uniform, optimizer=Nadam, total=   1.2s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=normal, optimizer=Adam \n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 2ms/step - loss: 0.7006 - acc: 0.1690\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 0s 10us/step - loss: 0.6983 - acc: 0.2218\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 0s 13us/step - loss: 0.6961 - acc: 0.3345\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 0s 10us/step - loss: 0.6940 - acc: 0.4507\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 0s 12us/step - loss: 0.6918 - acc: 0.5775\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 0s 9us/step - loss: 0.6897 - acc: 0.6761\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 0s 42us/step - loss: 0.6876 - acc: 0.7993\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 0s 11us/step - loss: 0.6855 - acc: 0.8380\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 0s 18us/step - loss: 0.6834 - acc: 0.8697\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 0s 17us/step - loss: 0.6812 - acc: 0.9014\n",
      "285/285 [==============================] - 0s 768us/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=normal, optimizer=Adam, total=   1.6s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=normal, optimizer=Adam \n",
      "Epoch 1/10\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.7111 - acc: 0.1053\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 0s 9us/step - loss: 0.7085 - acc: 0.1368\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 0s 8us/step - loss: 0.7051 - acc: 0.1754\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.7017 - acc: 0.2456\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.6983 - acc: 0.3298\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 0s 7us/step - loss: 0.6949 - acc: 0.4456\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 0s 7us/step - loss: 0.6916 - acc: 0.5614\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 0s 8us/step - loss: 0.6883 - acc: 0.6491\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 0s 8us/step - loss: 0.6850 - acc: 0.7228\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 0s 21us/step - loss: 0.6817 - acc: 0.7579\n",
      "284/284 [==============================] - 0s 526us/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=normal, optimizer=Adam, total=   1.2s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=normal, optimizer=Nadam \n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 2ms/step - loss: 0.6863 - acc: 0.7500\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 0s 35us/step - loss: 0.6823 - acc: 0.8169\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 0s 29us/step - loss: 0.6784 - acc: 0.8627\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 0s 23us/step - loss: 0.6751 - acc: 0.8944\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 0s 9us/step - loss: 0.6715 - acc: 0.9014\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 0s 10us/step - loss: 0.6675 - acc: 0.9120\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 0s 13us/step - loss: 0.6630 - acc: 0.9155\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 0s 40us/step - loss: 0.6581 - acc: 0.9190\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 0s 52us/step - loss: 0.6523 - acc: 0.9296\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 0s 65us/step - loss: 0.6463 - acc: 0.9296\n",
      "285/285 [==============================] - 0s 2ms/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=normal, optimizer=Nadam, total=   2.0s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=normal, optimizer=Nadam \n",
      "Epoch 1/10\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.6871 - acc: 0.6456\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 0s 6us/step - loss: 0.6809 - acc: 0.7544\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 0s 8us/step - loss: 0.6764 - acc: 0.7789\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 0s 6us/step - loss: 0.6722 - acc: 0.8175\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.6679 - acc: 0.8456\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.6635 - acc: 0.8632\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 0s 9us/step - loss: 0.6588 - acc: 0.8842\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.6537 - acc: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.6483 - acc: 0.8982\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.6424 - acc: 0.9053\n",
      "284/284 [==============================] - 0s 795us/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=8, kernel_initializer=normal, optimizer=Nadam, total=   2.3s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=uniform, optimizer=Adam \n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 2ms/step - loss: 0.6990 - acc: 0.0810\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 0s 6us/step - loss: 0.6975 - acc: 0.1725\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 0s 7us/step - loss: 0.6955 - acc: 0.3275\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 0s 6us/step - loss: 0.6935 - acc: 0.5246\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 0s 9us/step - loss: 0.6914 - acc: 0.6514\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 0s 14us/step - loss: 0.6894 - acc: 0.7676\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 0s 16us/step - loss: 0.6873 - acc: 0.8169\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 0s 18us/step - loss: 0.6852 - acc: 0.8556\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 0s 11us/step - loss: 0.6830 - acc: 0.8768\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 0s 8us/step - loss: 0.6808 - acc: 0.9014\n",
      "285/285 [==============================] - 0s 898us/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=uniform, optimizer=Adam, total=   1.7s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=uniform, optimizer=Adam \n",
      "Epoch 1/10\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.6956 - acc: 0.3684\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 0s 6us/step - loss: 0.6936 - acc: 0.4807\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 0s 8us/step - loss: 0.6917 - acc: 0.5965\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 0s 8us/step - loss: 0.6896 - acc: 0.6772\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 0s 9us/step - loss: 0.6876 - acc: 0.7333\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 0s 7us/step - loss: 0.6855 - acc: 0.7965\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 0s 8us/step - loss: 0.6834 - acc: 0.8175\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.6811 - acc: 0.8316\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 0s 11us/step - loss: 0.6788 - acc: 0.8491\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 0s 11us/step - loss: 0.6765 - acc: 0.8596\n",
      "284/284 [==============================] - 0s 766us/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=uniform, optimizer=Adam, total=   2.2s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=uniform, optimizer=Nadam \n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.6952 - acc: 0.2465\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 0s 49us/step - loss: 0.6895 - acc: 0.8521\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 0s 27us/step - loss: 0.6858 - acc: 0.9120\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 0s 30us/step - loss: 0.6827 - acc: 0.9366\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 0s 23us/step - loss: 0.6791 - acc: 0.9472\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 0s 44us/step - loss: 0.6751 - acc: 0.9401\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 0s 24us/step - loss: 0.6701 - acc: 0.9366\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 0s 50us/step - loss: 0.6647 - acc: 0.9366\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 0s 36us/step - loss: 0.6584 - acc: 0.9401\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 0s 83us/step - loss: 0.6513 - acc: 0.9401\n",
      "285/285 [==============================] - 0s 1ms/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=uniform, optimizer=Nadam, total=   2.1s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=uniform, optimizer=Nadam \n",
      "Epoch 1/10\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.6925 - acc: 0.5509\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 0s 12us/step - loss: 0.6881 - acc: 0.8491\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 0s 9us/step - loss: 0.6848 - acc: 0.8982\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 0s 8us/step - loss: 0.6816 - acc: 0.9193\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 0s 13us/step - loss: 0.6782 - acc: 0.9193\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 0s 13us/step - loss: 0.6742 - acc: 0.9158\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 0s 17us/step - loss: 0.6700 - acc: 0.9263\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 0s 12us/step - loss: 0.6653 - acc: 0.9333\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.6600 - acc: 0.9368\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.6541 - acc: 0.9404\n",
      "284/284 [==============================] - 1s 2ms/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=uniform, optimizer=Nadam, total=   2.1s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=normal, optimizer=Adam \n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 0.6755 - acc: 0.8803\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 0s 6us/step - loss: 0.6725 - acc: 0.9014\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 0s 8us/step - loss: 0.6694 - acc: 0.9190\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 0s 7us/step - loss: 0.6662 - acc: 0.9331\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 0s 8us/step - loss: 0.6631 - acc: 0.9401\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 0s 7us/step - loss: 0.6598 - acc: 0.9437\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 0s 6us/step - loss: 0.6566 - acc: 0.9507\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 0s 9us/step - loss: 0.6532 - acc: 0.9437\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 0s 6us/step - loss: 0.6498 - acc: 0.9507\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 0s 9us/step - loss: 0.6463 - acc: 0.9542\n",
      "285/285 [==============================] - 0s 958us/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=normal, optimizer=Adam, total=   1.8s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=normal, optimizer=Adam \n",
      "Epoch 1/10\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.6926 - acc: 0.5263\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.6891 - acc: 0.6561\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.6857 - acc: 0.7544\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.6826 - acc: 0.8351\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.6793 - acc: 0.8702\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.6761 - acc: 0.8737\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 0s 16us/step - loss: 0.6729 - acc: 0.8877\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 0s 24us/step - loss: 0.6696 - acc: 0.8947\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 0s 28us/step - loss: 0.6663 - acc: 0.8947\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.6629 - acc: 0.8982\n",
      "284/284 [==============================] - 0s 1ms/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=normal, optimizer=Adam, total=   1.7s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=normal, optimizer=Nadam \n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 0.6851 - acc: 0.6866\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 0s 12us/step - loss: 0.6746 - acc: 0.8063\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 0s 7us/step - loss: 0.6690 - acc: 0.8275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "284/284 [==============================] - 0s 9us/step - loss: 0.6636 - acc: 0.8415\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 0s 6us/step - loss: 0.6579 - acc: 0.8627\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 0s 7us/step - loss: 0.6518 - acc: 0.8768\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 0s 9us/step - loss: 0.6452 - acc: 0.8908\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 0s 6us/step - loss: 0.6381 - acc: 0.9014\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 0s 6us/step - loss: 0.6305 - acc: 0.9049\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 0s 11us/step - loss: 0.6224 - acc: 0.9085\n",
      "285/285 [==============================] - 0s 1ms/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=normal, optimizer=Nadam, total=   1.7s\n",
      "[CV] batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=normal, optimizer=Nadam \n",
      "Epoch 1/10\n",
      "285/285 [==============================] - 1s 4ms/step - loss: 0.6913 - acc: 0.5404\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 0s 10us/step - loss: 0.6833 - acc: 0.7439\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 0s 14us/step - loss: 0.6774 - acc: 0.8175\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.6720 - acc: 0.8421\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 0s 13us/step - loss: 0.6666 - acc: 0.8632\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 0s 12us/step - loss: 0.6610 - acc: 0.8807\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 0s 20us/step - loss: 0.6551 - acc: 0.8947\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 0s 13us/step - loss: 0.6490 - acc: 0.9123\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 0s 15us/step - loss: 0.6425 - acc: 0.9158\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 0s 22us/step - loss: 0.6356 - acc: 0.9158\n",
      "284/284 [==============================] - 0s 1ms/step\n",
      "[CV]  batch_size=1024, dropout_rate=0.0, epochs=10, first_neuron=9, kernel_initializer=normal, optimizer=Nadam, total=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   28.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "569/569 [==============================] - 1s 2ms/step - loss: 0.7011 - acc: 0.2794\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 0s 7us/step - loss: 0.6983 - acc: 0.3673\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 0s 6us/step - loss: 0.6955 - acc: 0.4587\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 0s 10us/step - loss: 0.6927 - acc: 0.5536\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 0s 7us/step - loss: 0.6900 - acc: 0.6274\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 0s 8us/step - loss: 0.6874 - acc: 0.6837\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 0s 14us/step - loss: 0.6847 - acc: 0.7258\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 0s 5us/step - loss: 0.6821 - acc: 0.7645\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 0s 6us/step - loss: 0.6794 - acc: 0.8049\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 0s 12us/step - loss: 0.6767 - acc: 0.8225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, verbose=2)\n",
    "grid_result = grid.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919156413610455 6\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_score_, grid_result.best_index_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8400703123877045 (0.026643145661219843) with: {'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'first_neuron': 8, 'kernel_initializer': 'uniform', 'optimizer': 'Adam'}\n",
      "0.8875219421772211 (0.00019767849911226908) with: {'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'first_neuron': 8, 'kernel_initializer': 'uniform', 'optimizer': 'Nadam'}\n",
      "0.7943760879429447 (0.058357953306975886) with: {'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'first_neuron': 8, 'kernel_initializer': 'normal', 'optimizer': 'Adam'}\n",
      "0.8699472772844646 (0.0037435235384426875) with: {'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'first_neuron': 8, 'kernel_initializer': 'normal', 'optimizer': 'Nadam'}\n",
      "0.8084358553056767 (0.004935763604323333) with: {'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'first_neuron': 9, 'kernel_initializer': 'uniform', 'optimizer': 'Adam'}\n",
      "0.8980667890689494 (0.00685073867427026) with: {'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'first_neuron': 9, 'kernel_initializer': 'uniform', 'optimizer': 'Nadam'}\n",
      "0.919156413610455 (0.00014206745141989848) with: {'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'first_neuron': 9, 'kernel_initializer': 'normal', 'optimizer': 'Adam'}\n",
      "0.8769771776216101 (0.02087345475972185) with: {'batch_size': 1024, 'dropout_rate': 0.0, 'epochs': 10, 'first_neuron': 9, 'kernel_initializer': 'normal', 'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"{mean} ({std}) with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "175.59375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
